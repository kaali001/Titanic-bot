# ğŸš¢ Titanic Dataset Chat Agent

A smart chatbot that interacts with the **Titanic dataset** using **FastAPI**, **LangChain**, and **Streamlit**. Users can ask natural language questions about the dataset, get **text-based insights**, and generate **visualizations** dynamically.

---

## âœ¨ Features

âœ… **Natural Language Queries** - Ask questions like *"How many male passengers survived?"*  
âœ… **AI-Powered Responses** - Uses an LLM to process and analyze the Titanic dataset.  
âœ… **Interactive Visualizations** - Generates graphs & charts based on queries.  
âœ… **Streamlit UI** - Clean and intuitive frontend for interacting with the chatbot.  
âœ… **FastAPI Backend** - Serves API responses efficiently.  
  

---

## ğŸ“Œ Tech Stack

- **Backend**: FastAPI, LangChain, OpenAI API (or alternative LLMs like DeepSeek, Grok, etc.)  
- **Frontend**: Streamlit  
- **Data Handling**: Pandas  
- **Visualization**: Matplotlib, Seaborn  


---

## ğŸš€ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/Titanic-Bot.git
cd Titanic-Bot
```

### 2ï¸âƒ£ Create a Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # On macOS/Linux
venv\Scripts\activate    # On Windows
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Up Environment Variables
Create a **.env** file in the `backend/` folder:
```
OPENAI_API_KEY=your_api_key_here
```


### 5ï¸âƒ£ Start the Backend
```bash
uvicorn backend.main:app --reload
```

### 6ï¸âƒ£ Start the Frontend (Streamlit)
```bash
streamlit run frontend/app.py
```

---

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET`  | `/query?question=your_query` | Get AI response & visualization |

---

